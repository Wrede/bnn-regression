{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_bnn import run_bnn, bnn_experiment\n",
    "from run_sbi import run_snpe, sbi_experiment\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ABC-SMC (Reproducibility)\n",
    "run the script run_abc.py to generate all the necessary data from the ABC-SMC sampler. Alternatively one can directly discover and tune the notebook: abc_smc.ipynb.\n",
    "\n",
    "Will compute and store the following files \n",
    "* smcabc_post_10gen - posterior samples\n",
    "* smcabc_trails_10gen.npy - number of simulated proposals\n",
    "\n",
    "Obs ABC-SMC requre many proposals, therefore this takes some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs to stop the script, interupt the kernel several times... \n",
    "%run run_abc.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SNPE-C (Reproducibility)\n",
    "run the SNPE-C (sbi package) script.\n",
    "\n",
    "### Generating the following files\n",
    "* data/sbi_data_post.npy - posterior samples\n",
    "* data/sbi_data_time.npy - elapsed times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbi_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom SNPE (Testing)\n",
    "For testing the script with fewer runs and other parameters. Obs that these results might not work for all plots in plotting.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 'data'\n",
    "sbi_post, sbi_time, sbi_post_object = run_snpe(total_runs=1, num_generation=6, seed=2, nde='maf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obs need \"data\" folder \n",
    "np.save(f'{ID}/sbi_{ID}_post', sbi_post)\n",
    "np.save(f'{ID}/sbi_{ID}_time', sbi_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take DirectPosterior to get the NN\n",
    "test = sbi_post_object[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of trainable weights/parameters\n",
    "def count_parameters(model):\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        total_params+=param\n",
    "        print(name,':', param)\n",
    "    print(f\"Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(test.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BNN (Reproducibility)\n",
    "\n",
    "\n",
    "### The following files are produced\n",
    "posterior samples from 4 bins per parameter, repeated 10 times, a 6 step iteration, with 0.05 threshold. With the time elapsed.\n",
    "* data/bcnn_data_post.npy' - posterior samples\n",
    "* data/bcnn_data_time.npy' - time elapsed \n",
    "\n",
    "posterior samples from 3 bins per parameter, repeated 10 times, a 6 step iteration, with 0.05 threshold.\n",
    "* data/bcnn_data_bins3_post.npy - posterior samples\n",
    "\n",
    "posterior samples from 5 bins, repeated 10 times, a 6 step iteration, with 0.05 threshold.\n",
    "* data/bcnn_data_bins5_post.npy - posterior samples\n",
    "\n",
    "posterior samples from 4 bins, repeated 10 times, a 6 step iteration, with no threshold.\n",
    "* data/bcnn_data_no_thresh_post.npy - posterior samples\n",
    "\n",
    "posterior samples from 4 bins, repeated 10 times, a 6 step iteration, with exponential decreasing threshold.\n",
    "* data/bcnn_data_exp_thresh_post.npy - posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#in case CUDA is causing problems...\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom BNN (Testing)\n",
    "For testing the script with fewer runs and other parameters.\n",
    "Obs that these results might not work for all plots in plotting.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting run 0\n",
      "starting round 0\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_flipout (Conv1DFlipou (None, 100, 25)           275       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 10, 25)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_flipout_1 (Conv1DFlip (None, 10, 6)             1506      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_flipout (DenseFlipout) (None, 20)                260       \n",
      "_________________________________________________________________\n",
      "dense_flipout_1 (DenseFlipou (None, 2)                 82        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 15        \n",
      "_________________________________________________________________\n",
      "multivariate_normal_tri_l (M ((None, 2), (None, 2))    0         \n",
      "=================================================================\n",
      "Total params: 2,138\n",
      "Trainable params: 2,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.5066\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.3459\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.2347\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.1867\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.1856\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.1251\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.1223\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.0873\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.0654\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 50ms/step - loss: 5.0195 - val_loss: 4.9595\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.9888\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.9517\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.9179\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.8921\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.8524\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.8220\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.7657\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.7557\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.7181\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 4.6802 - val_loss: 4.5923\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.6168\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.5696\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.5421\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.4627\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.4330\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.3869\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.3683\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.3400\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.3073\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 4.2543 - val_loss: 4.2441\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.2622\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.2432\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.2457\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1975\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1929\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1663\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.2352\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1607\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1500\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 4.1453 - val_loss: 4.1058\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1645\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1268\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.0938\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.0707\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.0820\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.0258\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.0040\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.0158\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.9693\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.9666 - val_loss: 4.0127\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9989\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9454\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9268\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9240\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9423\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.9208\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8992\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.9039\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8847\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.8774 - val_loss: 3.8354\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8527\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8526\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8544\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7959\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8164\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8356\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7804\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7661\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.7775\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.7675 - val_loss: 3.7726\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6904\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7445\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8043\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7216\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7191\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6625\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6795\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6919\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6554\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.6340 - val_loss: 3.6065\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6260\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6594\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.5985\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6301\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6290\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.5740\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5223\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5989\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.5375\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.5861 - val_loss: 3.5044\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6888\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5726\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5479\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5739\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5731\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.5692\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.4718\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5119\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.4562\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.4830 - val_loss: 3.5153\n",
      "starting round 1\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.4193 - val_loss: 3.4053\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4308 - val_loss: 3.3246\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3670 - val_loss: 3.3330\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3821 - val_loss: 3.3494\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3263 - val_loss: 3.2979\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.3377 - val_loss: 3.3414\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2900 - val_loss: 3.2648\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2804 - val_loss: 3.2887\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3062 - val_loss: 3.2560\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2556 - val_loss: 3.2708\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2495 - val_loss: 3.2980\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.2549 - val_loss: 3.1859\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2647 - val_loss: 3.2451\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2546 - val_loss: 3.1601\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1857 - val_loss: 3.1763\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2156 - val_loss: 3.2421\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2071 - val_loss: 3.1642\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1369 - val_loss: 3.4666\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1366 - val_loss: 3.0980\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2449 - val_loss: 3.2325\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1737 - val_loss: 3.1551\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.1785 - val_loss: 3.1780\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1391 - val_loss: 3.1439\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1298 - val_loss: 3.0820\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1140 - val_loss: 3.1817\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1010 - val_loss: 3.0739\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0678 - val_loss: 3.1621\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0690 - val_loss: 3.1247\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1435 - val_loss: 3.1134\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1222 - val_loss: 3.1280\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1105 - val_loss: 3.1179\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0663 - val_loss: 3.0552\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0326 - val_loss: 3.0526\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0386 - val_loss: 3.0422\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0218 - val_loss: 3.1330\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0103 - val_loss: 2.9627\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0201 - val_loss: 3.0171\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9817 - val_loss: 3.0056\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9692 - val_loss: 3.0292\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9719 - val_loss: 2.9940\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0021 - val_loss: 3.0152\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9492 - val_loss: 2.9573\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9510 - val_loss: 2.8959\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9424 - val_loss: 2.9109\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9336 - val_loss: 2.8474\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8887 - val_loss: 2.8567\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9564 - val_loss: 2.8606\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.9153 - val_loss: 2.8829\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9419 - val_loss: 2.9135\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8900 - val_loss: 2.8684\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9073 - val_loss: 2.8146\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8875 - val_loss: 2.9708\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8953 - val_loss: 2.8721\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8510 - val_loss: 2.8784\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8776 - val_loss: 2.8618\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8405 - val_loss: 2.9299\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8245 - val_loss: 2.9034\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8137 - val_loss: 2.8916\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8312 - val_loss: 2.8114\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8187 - val_loss: 2.8352\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8031 - val_loss: 2.9254\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7962 - val_loss: 2.7948\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8119 - val_loss: 2.7510\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7754 - val_loss: 2.8393\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7840 - val_loss: 2.8283\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7415 - val_loss: 2.8449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7442 - val_loss: 2.7247\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7257 - val_loss: 2.9071\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7563 - val_loss: 2.7870\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7101 - val_loss: 2.8265\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7583 - val_loss: 2.7259\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6908 - val_loss: 2.7321\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7308 - val_loss: 2.7186\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6967 - val_loss: 2.7463\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6695 - val_loss: 2.7458\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7217 - val_loss: 2.6846\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7397 - val_loss: 2.6597\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6547 - val_loss: 2.6772\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6819 - val_loss: 2.7504\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7059 - val_loss: 2.6841\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6542 - val_loss: 2.7363\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6546 - val_loss: 2.6672\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6347 - val_loss: 2.5485\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6102 - val_loss: 2.7942\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6276 - val_loss: 2.6300\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6187 - val_loss: 2.6565\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6057 - val_loss: 2.6751\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.6128 - val_loss: 2.5965\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5775 - val_loss: 2.6368\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5790 - val_loss: 2.5478\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5621 - val_loss: 2.5943\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5533 - val_loss: 2.6086\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5817 - val_loss: 2.5967\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5687 - val_loss: 2.5233\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5477 - val_loss: 2.5603\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5612 - val_loss: 2.5169\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5266 - val_loss: 2.6174\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4841 - val_loss: 2.6707\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4778 - val_loss: 2.5303\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5443 - val_loss: 2.6014\n",
      "starting round 2\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.0225 - val_loss: 3.5384\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.4049 - val_loss: 3.2571\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.2295 - val_loss: 3.1877\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.1448 - val_loss: 3.0849\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.0553 - val_loss: 3.0658\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.0343 - val_loss: 2.9658\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.9447 - val_loss: 2.8969\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.9506 - val_loss: 2.9116\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.9122 - val_loss: 2.9131\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.8731 - val_loss: 2.7953\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.8639 - val_loss: 2.8837\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.8767 - val_loss: 2.7848\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.8099 - val_loss: 2.7645\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.7814 - val_loss: 2.7785\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.7931 - val_loss: 2.8033\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.7989 - val_loss: 2.8241\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.8077 - val_loss: 2.7744\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.7550 - val_loss: 2.7149\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.7212 - val_loss: 2.7212\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.7403 - val_loss: 2.7545\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.6979 - val_loss: 2.7161\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.7016 - val_loss: 2.7322\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.6666 - val_loss: 2.6343\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.6723 - val_loss: 2.6275\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.6740 - val_loss: 2.6089\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.6432 - val_loss: 2.6585\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.6572 - val_loss: 2.5815\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5741 - val_loss: 2.6265\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5961 - val_loss: 2.5566\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.6523 - val_loss: 2.6497\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5797 - val_loss: 2.5765\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5862 - val_loss: 2.5440\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5525 - val_loss: 2.5649\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5358 - val_loss: 2.5695\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5103 - val_loss: 2.4916\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5243 - val_loss: 2.4659\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4927 - val_loss: 2.5187\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5157 - val_loss: 2.4924\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4953 - val_loss: 2.4691\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5218 - val_loss: 2.4443\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4672 - val_loss: 2.4715\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4585 - val_loss: 2.4630\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4832 - val_loss: 2.5140\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4492 - val_loss: 2.4767\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4254 - val_loss: 2.3677\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4146 - val_loss: 2.3544\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.5050 - val_loss: 2.4219\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4088 - val_loss: 2.4691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4272 - val_loss: 2.4453\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4080 - val_loss: 2.4790\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3783 - val_loss: 2.3699\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3666 - val_loss: 2.3000\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3233 - val_loss: 2.4376\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3663 - val_loss: 2.3054\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3589 - val_loss: 2.3287\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3149 - val_loss: 2.2970\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3380 - val_loss: 2.2875\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2938 - val_loss: 2.3516\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.3121 - val_loss: 2.2562\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3151 - val_loss: 2.2980\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2969 - val_loss: 2.3061\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2877 - val_loss: 2.2754\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2818 - val_loss: 2.2959\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2578 - val_loss: 2.3168\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2846 - val_loss: 2.2868\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2507 - val_loss: 2.2821\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2458 - val_loss: 2.2144\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2122 - val_loss: 2.2190\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2446 - val_loss: 2.2705\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2240 - val_loss: 2.2162\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2033 - val_loss: 2.2523\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1879 - val_loss: 2.1888\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1593 - val_loss: 2.2216\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1905 - val_loss: 2.1566\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1610 - val_loss: 2.1038\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1741 - val_loss: 2.1238\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1700 - val_loss: 2.2295\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1785 - val_loss: 2.1648\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1443 - val_loss: 2.0771\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1844 - val_loss: 2.1780\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1359 - val_loss: 2.1216\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.1249 - val_loss: 2.0789\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0901 - val_loss: 2.2042\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1432 - val_loss: 2.1632\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1062 - val_loss: 2.1271\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0747 - val_loss: 2.1573\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0720 - val_loss: 2.0989\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0349 - val_loss: 2.1132\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0996 - val_loss: 2.1399\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0862 - val_loss: 2.1070\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0829 - val_loss: 2.0738\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0771 - val_loss: 2.1052\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0635 - val_loss: 2.0773\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0589 - val_loss: 2.0487\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0624 - val_loss: 2.0770\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0112 - val_loss: 1.9949\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9991 - val_loss: 1.9617\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9894 - val_loss: 2.0171\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0177 - val_loss: 1.9717\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9696 - val_loss: 1.9758\n",
      "starting round 3\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.9303 - val_loss: 2.0457\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.8799 - val_loss: 2.0198\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.8968 - val_loss: 1.9697\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.9018 - val_loss: 1.9945\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.8854 - val_loss: 2.0252\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.8597 - val_loss: 1.9885\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.8525 - val_loss: 1.9897\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.8200 - val_loss: 1.9525\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.8476 - val_loss: 1.9254\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.8607 - val_loss: 1.9228\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.8078 - val_loss: 1.9182\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.7670 - val_loss: 1.9724\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7769 - val_loss: 1.8824\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7646 - val_loss: 1.9344\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7941 - val_loss: 1.9099\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7574 - val_loss: 1.9156\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7703 - val_loss: 1.9223\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7653 - val_loss: 1.8908\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7422 - val_loss: 1.8685\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7375 - val_loss: 1.8882\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7220 - val_loss: 1.8655\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7196 - val_loss: 1.8388\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.7166 - val_loss: 1.8023\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6774 - val_loss: 1.8374\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6842 - val_loss: 1.8257\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6992 - val_loss: 1.8105\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6986 - val_loss: 1.7861\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6823 - val_loss: 1.8315\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6888 - val_loss: 1.8441\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6577 - val_loss: 1.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6351 - val_loss: 1.7530\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6652 - val_loss: 1.7874\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6381 - val_loss: 1.7985\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6256 - val_loss: 1.7996\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6219 - val_loss: 1.7427\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.6038 - val_loss: 1.7332\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5881 - val_loss: 1.7476\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5877 - val_loss: 1.7586\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5939 - val_loss: 1.6552\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5769 - val_loss: 1.7614\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5812 - val_loss: 1.7164\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5831 - val_loss: 1.6897\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5639 - val_loss: 1.6645\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.5746 - val_loss: 1.6737\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5794 - val_loss: 1.6698\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5225 - val_loss: 1.6638\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5376 - val_loss: 1.6988\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.5345 - val_loss: 1.6778\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5337 - val_loss: 1.6851\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5125 - val_loss: 1.6145\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5091 - val_loss: 1.7159\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5111 - val_loss: 1.5914\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4881 - val_loss: 1.5889\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5009 - val_loss: 1.6485\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4588 - val_loss: 1.6170\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5003 - val_loss: 1.6030\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4718 - val_loss: 1.6132\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4903 - val_loss: 1.6154\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4595 - val_loss: 1.6933\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4905 - val_loss: 1.5897\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4499 - val_loss: 1.5685\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4511 - val_loss: 1.6006\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4608 - val_loss: 1.6101\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4515 - val_loss: 1.6273\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4493 - val_loss: 1.5983\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4544 - val_loss: 1.5522\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4299 - val_loss: 1.5618\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4242 - val_loss: 1.5524\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4113 - val_loss: 1.5658\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4149 - val_loss: 1.5495\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3996 - val_loss: 1.5422\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3929 - val_loss: 1.5663\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4283 - val_loss: 1.5716\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3709 - val_loss: 1.5450\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3972 - val_loss: 1.4865\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3763 - val_loss: 1.5662\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3651 - val_loss: 1.5777\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3771 - val_loss: 1.5376\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3663 - val_loss: 1.5865\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3742 - val_loss: 1.5044\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3457 - val_loss: 1.5156\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3607 - val_loss: 1.5504\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3532 - val_loss: 1.5003\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3576 - val_loss: 1.4648\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3492 - val_loss: 1.4838\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3292 - val_loss: 1.4466\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3394 - val_loss: 1.5742\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3014 - val_loss: 1.4421\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3401 - val_loss: 1.5005\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3410 - val_loss: 1.5128\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3336 - val_loss: 1.5089\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2973 - val_loss: 1.4611\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.2969 - val_loss: 1.4765\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3117 - val_loss: 1.5230\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2993 - val_loss: 1.4692\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3296 - val_loss: 1.3983\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2742 - val_loss: 1.4474\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2895 - val_loss: 1.4005\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2696 - val_loss: 1.4173\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2989 - val_loss: 1.5245\n",
      "starting round 4\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2129 - val_loss: 1.1828\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2214 - val_loss: 1.2178\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2079 - val_loss: 1.2008\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2013 - val_loss: 1.2223\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1811 - val_loss: 1.1766\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1915 - val_loss: 1.1885\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1832 - val_loss: 1.1912\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1680 - val_loss: 1.1982\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1821 - val_loss: 1.2177\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1737 - val_loss: 1.1870\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1649 - val_loss: 1.1800\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1737 - val_loss: 1.2149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1411 - val_loss: 1.1601\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1417 - val_loss: 1.1571\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1398 - val_loss: 1.1178\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1421 - val_loss: 1.1783\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1318 - val_loss: 1.1290\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1439 - val_loss: 1.1455\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1384 - val_loss: 1.1252\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1157 - val_loss: 1.1338\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1342 - val_loss: 1.1620\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1071 - val_loss: 1.1183\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1405 - val_loss: 1.1209\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0783 - val_loss: 1.0888\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0959 - val_loss: 1.1256\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1071 - val_loss: 1.1180\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0775 - val_loss: 1.0467\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0935 - val_loss: 1.1105\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1071 - val_loss: 1.1275\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0860 - val_loss: 1.0708\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0931 - val_loss: 1.1481\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0657 - val_loss: 1.1132\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0771 - val_loss: 1.0216\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0885 - val_loss: 1.1230\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0903 - val_loss: 1.0802\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0695 - val_loss: 1.0826\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0560 - val_loss: 1.0624\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0623 - val_loss: 1.0299\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0482 - val_loss: 1.0962\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0698 - val_loss: 1.0454\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0494 - val_loss: 1.0168\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0206 - val_loss: 1.0759\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0459 - val_loss: 1.0635\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0476 - val_loss: 1.0757\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0604 - val_loss: 1.0061\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0211 - val_loss: 1.0490\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0358 - val_loss: 1.0635\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0449 - val_loss: 1.0156\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0346 - val_loss: 1.0929\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0382 - val_loss: 1.0234\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0336 - val_loss: 1.0118\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0069 - val_loss: 1.0288\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0185 - val_loss: 0.9869\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0085 - val_loss: 1.0071\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0100 - val_loss: 1.0425\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0079 - val_loss: 1.0624\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0200 - val_loss: 0.9796\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0037 - val_loss: 1.0073\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0075 - val_loss: 0.9924\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9882 - val_loss: 0.9702\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0261 - val_loss: 1.0218\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9841 - val_loss: 1.0278\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0044 - val_loss: 1.0363\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9999 - val_loss: 1.0109\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9813 - val_loss: 1.0687\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9760 - val_loss: 0.9771\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9937 - val_loss: 0.9420\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0029 - val_loss: 1.0250\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9816 - val_loss: 1.0071\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9852 - val_loss: 0.9827\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9575 - val_loss: 1.0035\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9641 - val_loss: 1.0272\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0126 - val_loss: 0.9907\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9739 - val_loss: 0.9248\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9806 - val_loss: 0.9678\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9814 - val_loss: 0.9403\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9714 - val_loss: 0.9664\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9670 - val_loss: 0.9966\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9751 - val_loss: 0.9787\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9460 - val_loss: 0.9943\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9662 - val_loss: 0.9393\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9684 - val_loss: 0.9462\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9721 - val_loss: 0.9760\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9729 - val_loss: 0.9495\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9503 - val_loss: 0.9540\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9377 - val_loss: 0.9614\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9472 - val_loss: 0.9753\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9332 - val_loss: 0.9693\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9227 - val_loss: 0.9399\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9583 - val_loss: 0.9178\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9547 - val_loss: 0.9285\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9344 - val_loss: 0.9058\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9294 - val_loss: 0.9268\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9392 - val_loss: 0.9607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9634 - val_loss: 0.9703\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9302 - val_loss: 0.9071\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9212 - val_loss: 0.9246\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9240 - val_loss: 0.9138\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9319 - val_loss: 0.9197\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9120 - val_loss: 0.9289\n",
      "starting round 5\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8729 - val_loss: 0.8545\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8536 - val_loss: 0.8372\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8395 - val_loss: 0.9062\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8570 - val_loss: 0.8475\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8285 - val_loss: 0.8748\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8343 - val_loss: 0.8981\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8365 - val_loss: 0.8441\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8339 - val_loss: 0.9017\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8214 - val_loss: 0.8407\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8364 - val_loss: 0.8849\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8290 - val_loss: 0.8914\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8306 - val_loss: 0.8668\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8243 - val_loss: 0.8611\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8109 - val_loss: 0.8553\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8252 - val_loss: 0.8795\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8188 - val_loss: 0.8967\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8184 - val_loss: 0.8629\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7996 - val_loss: 0.9180\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8116 - val_loss: 0.8762\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8034 - val_loss: 0.8987\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8152 - val_loss: 0.8398\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8136 - val_loss: 0.8472\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8175 - val_loss: 0.8875\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8063 - val_loss: 0.8861\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8028 - val_loss: 0.8847\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7973 - val_loss: 0.7859\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8081 - val_loss: 0.8298\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8076 - val_loss: 0.8776\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7976 - val_loss: 0.8768\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7906 - val_loss: 0.9311\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7941 - val_loss: 0.8751\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7950 - val_loss: 0.8685\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7882 - val_loss: 0.8636\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8047 - val_loss: 0.8511\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7878 - val_loss: 0.8437\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7886 - val_loss: 0.8504\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7869 - val_loss: 0.8398\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7997 - val_loss: 0.9007\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7965 - val_loss: 0.8404\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7782 - val_loss: 0.7952\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7727 - val_loss: 0.8416\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7681 - val_loss: 0.8371\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7804 - val_loss: 0.8040\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7792 - val_loss: 0.8234\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7876 - val_loss: 0.8529\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7565 - val_loss: 0.8481\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7784 - val_loss: 0.8286\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8050 - val_loss: 0.8059\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7484 - val_loss: 0.8093\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7640 - val_loss: 0.8335\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7588 - val_loss: 0.8439\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7665 - val_loss: 0.8132\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7739 - val_loss: 0.8618\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7605 - val_loss: 0.7854\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7547 - val_loss: 0.7837\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7779 - val_loss: 0.8285\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7569 - val_loss: 0.8563\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7414 - val_loss: 0.8664\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7422 - val_loss: 0.8308\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.8411\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7345 - val_loss: 0.8211\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7417 - val_loss: 0.8158\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7731 - val_loss: 0.8381\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7532 - val_loss: 0.8272\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7728 - val_loss: 0.8544\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7334 - val_loss: 0.7767\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7402 - val_loss: 0.8126\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7499 - val_loss: 0.7680\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7377 - val_loss: 0.8048\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7279 - val_loss: 0.8103\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7530 - val_loss: 0.7648\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7211 - val_loss: 0.7819\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7343 - val_loss: 0.7842\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7153 - val_loss: 0.8377\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7349 - val_loss: 0.7870\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7153 - val_loss: 0.8411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7208 - val_loss: 0.7742\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7424 - val_loss: 0.8322\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7342 - val_loss: 0.8700\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7137 - val_loss: 0.7810\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7116 - val_loss: 0.7781\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7203 - val_loss: 0.8105\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7153 - val_loss: 0.7510\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7073 - val_loss: 0.8118\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7142 - val_loss: 0.7599\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7130 - val_loss: 0.7269\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7754 - val_loss: 0.8289\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7424 - val_loss: 0.7730\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7026 - val_loss: 0.7783\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7056 - val_loss: 0.7753\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7230 - val_loss: 0.7896\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.8071\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7296 - val_loss: 0.7807\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7111 - val_loss: 0.7918\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7195 - val_loss: 0.8079\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7042 - val_loss: 0.7835\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6880 - val_loss: 0.7934\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7195 - val_loss: 0.7708\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7056 - val_loss: 0.7836\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6855 - val_loss: 0.7933\n"
     ]
    }
   ],
   "source": [
    "ID = 'data'\n",
    "bcnn_post, bcnn_proposals, bcnn_time = run_bnn(total_runs=1, num_rounds=6, seed=3, \n",
    "                               ID=ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting run 0\n",
      "starting round 0\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_flipout (Conv1DFlipou (None, 100, 25)           275       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 10, 25)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_flipout_1 (Conv1DFlip (None, 10, 6)             1506      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_flipout (DenseFlipout) (None, 20)                260       \n",
      "_________________________________________________________________\n",
      "dense_flipout_1 (DenseFlipou (None, 2)                 82        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 15        \n",
      "_________________________________________________________________\n",
      "multivariate_normal_tri_l (M ((None, 2), (None, 2))    0         \n",
      "=================================================================\n",
      "Total params: 2,138\n",
      "Trainable params: 2,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.4753\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.3985\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.3569\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.3278\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.2881\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.2378\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.1743\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.1017\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.0094\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 4.8710 - val_loss: 4.7012\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.7146\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.6321\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.5947\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.5080\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.5249\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.4681\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.3923\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.3574\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.2966\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 4.2367 - val_loss: 4.2559\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.2186\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.2384\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1718\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1451\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1493\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.1225\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.0426\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.0195\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.0519\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 4.0245 - val_loss: 3.8918\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.0338\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9878\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9781\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9734\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9944\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8715\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9777\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9357\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8712\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.9022 - val_loss: 3.9007\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 3.9212\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9180\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8633\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8609\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8672\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8316\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8436\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8497\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8673\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.8626 - val_loss: 3.7223\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8044\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8316\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8321\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7791\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7425\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8063\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7739\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7806\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8018\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.8333 - val_loss: 3.7016\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7808\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7336\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7821\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7117\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7543\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6997\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7302\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7074\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7387\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.7941 - val_loss: 3.6320\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6511\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6936\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6771\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6696\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6986\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6559\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6008\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.5875\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.7079\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 3.6031 - val_loss: 3.5611\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6666\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.5902\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6359\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.5867\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6118\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5791\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6482\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6270\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5915\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.6454 - val_loss: 3.4927\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6054\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5723\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5923\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.5674\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6047\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5382\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5601\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5903\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5565\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.5091 - val_loss: 3.6626\n",
      "starting round 1\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 3.6700 - val_loss: 3.6011\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.6265 - val_loss: 3.5926\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5930 - val_loss: 3.6985\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5845 - val_loss: 3.5285\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5480 - val_loss: 3.5490\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5520 - val_loss: 3.4978\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5460 - val_loss: 3.5797\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5464 - val_loss: 3.4902\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5221 - val_loss: 3.5328\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4904 - val_loss: 3.4911\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.5193 - val_loss: 3.4673\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4639 - val_loss: 3.4681\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4846 - val_loss: 3.5238\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4856 - val_loss: 3.4399\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4579 - val_loss: 3.3807\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4427 - val_loss: 3.4265\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4349 - val_loss: 3.3460\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4203 - val_loss: 3.3473\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3864 - val_loss: 3.3765\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4246 - val_loss: 3.3771\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3919 - val_loss: 3.3663\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3548 - val_loss: 3.3491\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3588 - val_loss: 3.3062\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3482 - val_loss: 3.2466\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3262 - val_loss: 3.3742\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3162 - val_loss: 3.2768\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3407 - val_loss: 3.2825\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3189 - val_loss: 3.2429\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2773 - val_loss: 3.2442\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2809 - val_loss: 3.2271\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2780 - val_loss: 3.2062\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2514 - val_loss: 3.1595\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2122 - val_loss: 3.2066\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2598 - val_loss: 3.2034\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1884 - val_loss: 3.1548\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1740 - val_loss: 3.1630\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1664 - val_loss: 3.1216\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1450 - val_loss: 3.1076\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1156 - val_loss: 3.2028\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1795 - val_loss: 3.0625\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1587 - val_loss: 3.0911\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1213 - val_loss: 3.0693\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1217 - val_loss: 3.0968\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0985 - val_loss: 3.1022\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1102 - val_loss: 3.0661\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0694 - val_loss: 3.0248\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0501 - val_loss: 3.0845\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0520 - val_loss: 2.9656\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0297 - val_loss: 3.0424\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0873 - val_loss: 3.0232\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0195 - val_loss: 3.0072\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0614 - val_loss: 2.9606\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0165 - val_loss: 2.9710\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9900 - val_loss: 3.0089\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9641 - val_loss: 3.0503\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9506 - val_loss: 2.9303\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9296 - val_loss: 2.9207\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9851 - val_loss: 2.9899\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9652 - val_loss: 2.9292\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9450 - val_loss: 2.9244\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9511 - val_loss: 2.8574\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9215 - val_loss: 2.8583\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9006 - val_loss: 2.8754\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9112 - val_loss: 2.7963\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8635 - val_loss: 2.8330\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8678 - val_loss: 2.8339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.8685 - val_loss: 2.7926\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8231 - val_loss: 2.8078\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8808 - val_loss: 2.7991\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7984 - val_loss: 2.7508\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8656 - val_loss: 2.7968\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.8104 - val_loss: 2.8081\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7467 - val_loss: 2.8227\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7793 - val_loss: 2.7943\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7615 - val_loss: 2.7431\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7531 - val_loss: 2.8026\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.7388 - val_loss: 2.7562\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.7400 - val_loss: 2.8159\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7114 - val_loss: 2.6972\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7385 - val_loss: 2.6946\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6653 - val_loss: 2.6493\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7142 - val_loss: 2.6014\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6586 - val_loss: 2.7218\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6794 - val_loss: 2.6690\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6688 - val_loss: 2.7162\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6721 - val_loss: 2.5971\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6373 - val_loss: 2.5962\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6256 - val_loss: 2.6910\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6170 - val_loss: 2.6005\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6517 - val_loss: 2.6701\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5953 - val_loss: 2.6169\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6040 - val_loss: 2.5725\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.6239 - val_loss: 2.6323\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5807 - val_loss: 2.6055\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5865 - val_loss: 2.5897\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5557 - val_loss: 2.5525\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5473 - val_loss: 2.5603\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5382 - val_loss: 2.5128\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5206 - val_loss: 2.5414\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5204 - val_loss: 2.5483\n",
      "starting round 2\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.3398 - val_loss: 2.3084\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3474 - val_loss: 2.3189\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3414 - val_loss: 2.2647\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.3272 - val_loss: 2.2934\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3004 - val_loss: 2.2084\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2546 - val_loss: 2.2502\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2749 - val_loss: 2.1459\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2643 - val_loss: 2.2278\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2600 - val_loss: 2.2022\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2824 - val_loss: 2.2385\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2212 - val_loss: 2.1869\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2066 - val_loss: 2.1600\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.2001 - val_loss: 2.2465\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1911 - val_loss: 2.0835\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1991 - val_loss: 2.1609\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1657 - val_loss: 2.1430\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1291 - val_loss: 2.1429\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1426 - val_loss: 2.1566\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1439 - val_loss: 2.1076\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0710 - val_loss: 2.0554\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1100 - val_loss: 2.0734\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1137 - val_loss: 2.1077\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0610 - val_loss: 2.0084\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0614 - val_loss: 1.9928\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0853 - val_loss: 2.0297\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0463 - val_loss: 1.9832\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9950 - val_loss: 1.9915\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0469 - val_loss: 2.0364\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9774 - val_loss: 1.9285\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0273 - val_loss: 1.9852\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0028 - val_loss: 1.9629\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9963 - val_loss: 1.9682\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9869 - val_loss: 1.9376\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9604 - val_loss: 1.9197\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0171 - val_loss: 1.9363\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9548 - val_loss: 1.9112\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9261 - val_loss: 1.9107\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8970 - val_loss: 1.8907\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9222 - val_loss: 1.8772\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8965 - val_loss: 1.9031\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8788 - val_loss: 1.8838\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8880 - val_loss: 1.8645\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.8837 - val_loss: 1.8310\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9048 - val_loss: 1.9102\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8714 - val_loss: 1.8381\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8549 - val_loss: 1.7931\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8550 - val_loss: 1.8638\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8469 - val_loss: 1.7573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8211 - val_loss: 1.7209\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8431 - val_loss: 1.8674\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8295 - val_loss: 1.7664\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8104 - val_loss: 1.7846\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8162 - val_loss: 1.8212\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8477 - val_loss: 1.7362\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8101 - val_loss: 1.7323\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7931 - val_loss: 1.7564\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7798 - val_loss: 1.7704\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7561 - val_loss: 1.7619\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7498 - val_loss: 1.7743\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7442 - val_loss: 1.7307\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7366 - val_loss: 1.6378\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7153 - val_loss: 1.7356\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7577 - val_loss: 1.7156\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7143 - val_loss: 1.6653\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7144 - val_loss: 1.7251\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6901 - val_loss: 1.6747\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6746 - val_loss: 1.6692\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6720 - val_loss: 1.7176\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6896 - val_loss: 1.7009\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6612 - val_loss: 1.7179\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6678 - val_loss: 1.6023\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6544 - val_loss: 1.5998\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6456 - val_loss: 1.6337\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6485 - val_loss: 1.6173\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6588 - val_loss: 1.6254\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6439 - val_loss: 1.6145\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6134 - val_loss: 1.6202\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5962 - val_loss: 1.5251\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5777 - val_loss: 1.6158\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6082 - val_loss: 1.6057\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5896 - val_loss: 1.5245\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5777 - val_loss: 1.6104\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5751 - val_loss: 1.5589\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5565 - val_loss: 1.5905\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5637 - val_loss: 1.5519\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5268 - val_loss: 1.4983\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5488 - val_loss: 1.5381\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5152 - val_loss: 1.4950\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5216 - val_loss: 1.4830\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5221 - val_loss: 1.5628\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5381 - val_loss: 1.4776\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5041 - val_loss: 1.5076\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.4936 - val_loss: 1.4854\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.4870 - val_loss: 1.4850\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5114 - val_loss: 1.5620\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5106 - val_loss: 1.4779\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5041 - val_loss: 1.5372\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 1.4892 - val_loss: 1.4325\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.4595 - val_loss: 1.4909\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.4459 - val_loss: 1.4663\n",
      "starting round 3\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3426 - val_loss: 1.3004\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.3138 - val_loss: 1.3195\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2723 - val_loss: 1.3459\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2968 - val_loss: 1.2426\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2715 - val_loss: 1.2807\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2774 - val_loss: 1.2746\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2561 - val_loss: 1.2485\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2585 - val_loss: 1.2734\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2424 - val_loss: 1.2948\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2245 - val_loss: 1.2078\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2229 - val_loss: 1.2615\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2319 - val_loss: 1.1937\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2086 - val_loss: 1.1922\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2012 - val_loss: 1.1927\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2071 - val_loss: 1.1730\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1952 - val_loss: 1.1897\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1896 - val_loss: 1.1581\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1567 - val_loss: 1.1884\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1550 - val_loss: 1.1847\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1392 - val_loss: 1.1670\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1366 - val_loss: 1.1569\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1780 - val_loss: 1.1132\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1143 - val_loss: 1.1389\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1273 - val_loss: 1.1030\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1161 - val_loss: 1.1742\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0869 - val_loss: 1.1797\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1250 - val_loss: 1.1460\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1045 - val_loss: 1.1045\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1015 - val_loss: 1.0572\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0711 - val_loss: 1.0220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0858 - val_loss: 1.0697\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0673 - val_loss: 1.0643\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0771 - val_loss: 1.0504\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0380 - val_loss: 1.0580\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0370 - val_loss: 1.0496\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0326 - val_loss: 1.0376\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0422 - val_loss: 1.0577\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0420 - val_loss: 1.0350\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0181 - val_loss: 1.0315\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0463 - val_loss: 1.0688\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0298 - val_loss: 1.0182\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0039 - val_loss: 1.0697\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0147 - val_loss: 1.0276\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9850 - val_loss: 0.9746\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9991 - val_loss: 1.0154\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9955 - val_loss: 0.9782\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9739 - val_loss: 0.9465\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9914 - val_loss: 0.9581\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9591 - val_loss: 0.9534\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9499 - val_loss: 0.9499\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9880 - val_loss: 0.9638\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9396 - val_loss: 0.9800\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9541 - val_loss: 0.9655\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9249 - val_loss: 0.9283\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9654 - val_loss: 0.9554\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9258 - val_loss: 0.9443\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9085 - val_loss: 0.9362\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9005 - val_loss: 0.8781\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9024 - val_loss: 0.9395\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9107 - val_loss: 0.9509\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9045 - val_loss: 0.9343\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8855 - val_loss: 0.8654\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8923 - val_loss: 0.9178\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8940 - val_loss: 0.9446\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8793 - val_loss: 0.9201\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9029 - val_loss: 0.8816\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8718 - val_loss: 0.8916\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8767 - val_loss: 0.9133\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8576 - val_loss: 0.8532\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8521 - val_loss: 0.8596\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8770 - val_loss: 0.8743\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8081 - val_loss: 0.8641\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8352 - val_loss: 0.8828\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8014 - val_loss: 0.8767\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8043 - val_loss: 0.7970\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8392 - val_loss: 0.9031\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8484 - val_loss: 0.8474\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8171 - val_loss: 0.8855\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8177 - val_loss: 0.8701\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8296 - val_loss: 0.8566\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8574 - val_loss: 0.8270\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8021 - val_loss: 0.8269\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8073 - val_loss: 0.8345\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7916 - val_loss: 0.8318\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7968 - val_loss: 0.8147\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7834 - val_loss: 0.8518\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7612 - val_loss: 0.8376\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7612 - val_loss: 0.8459\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7631 - val_loss: 0.8105\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7568 - val_loss: 0.8411\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7665 - val_loss: 0.7628\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7808 - val_loss: 0.8228\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7513 - val_loss: 0.8061\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7622 - val_loss: 0.7653\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7665 - val_loss: 0.7614\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7542 - val_loss: 0.7663\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7404 - val_loss: 0.7452\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7487 - val_loss: 0.8017\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7352 - val_loss: 0.7342\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7145 - val_loss: 0.7771\n",
      "starting round 4\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.6660\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6362 - val_loss: 0.6503\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6138 - val_loss: 0.7077\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6119 - val_loss: 0.6755\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5926 - val_loss: 0.6370\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6201 - val_loss: 0.6645\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6028 - val_loss: 0.6324\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6045 - val_loss: 0.6553\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5820 - val_loss: 0.6478\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5646 - val_loss: 0.6453\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5786 - val_loss: 0.6002\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5929 - val_loss: 0.6004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5780 - val_loss: 0.6242\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5660 - val_loss: 0.5773\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6133 - val_loss: 0.6731\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5759 - val_loss: 0.6039\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5331 - val_loss: 0.5968\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5176 - val_loss: 0.6103\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5454 - val_loss: 0.6354\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5262 - val_loss: 0.5757\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5505 - val_loss: 0.6027\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - val_loss: 0.6308\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5312 - val_loss: 0.5981\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5229 - val_loss: 0.6192\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5277 - val_loss: 0.6015\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5235 - val_loss: 0.6199\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4975 - val_loss: 0.5813\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5025 - val_loss: 0.5542\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4914 - val_loss: 0.5537\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5217 - val_loss: 0.5944\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4797 - val_loss: 0.5772\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4925 - val_loss: 0.5966\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4998 - val_loss: 0.5491\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4768 - val_loss: 0.5584\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4853 - val_loss: 0.5709\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4933 - val_loss: 0.6035\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4791 - val_loss: 0.5708\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4806 - val_loss: 0.5413\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4613 - val_loss: 0.5953\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4957 - val_loss: 0.5502\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4597 - val_loss: 0.5051\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4578 - val_loss: 0.5469\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4782 - val_loss: 0.4971\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4531 - val_loss: 0.5052\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4582 - val_loss: 0.5462\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4592 - val_loss: 0.5314\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4500 - val_loss: 0.5092\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4384 - val_loss: 0.4776\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4613 - val_loss: 0.5363\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4216 - val_loss: 0.4999\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4737 - val_loss: 0.5147\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4351 - val_loss: 0.4864\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4314 - val_loss: 0.5018\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4337 - val_loss: 0.4803\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4187 - val_loss: 0.5088\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4195 - val_loss: 0.5005\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4132 - val_loss: 0.4861\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4143 - val_loss: 0.4662\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4217 - val_loss: 0.4983\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4077 - val_loss: 0.5027\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3935 - val_loss: 0.4755\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4278 - val_loss: 0.4877\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4152 - val_loss: 0.4600\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3982 - val_loss: 0.4698\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4195 - val_loss: 0.4892\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3929 - val_loss: 0.4979\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3922 - val_loss: 0.4827\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4077 - val_loss: 0.4583\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4060 - val_loss: 0.4665\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4034 - val_loss: 0.4821\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3925 - val_loss: 0.4493\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3767 - val_loss: 0.4754\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3865 - val_loss: 0.4599\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3620 - val_loss: 0.4778\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4046 - val_loss: 0.5255\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3656 - val_loss: 0.4563\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3717 - val_loss: 0.4446\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3769 - val_loss: 0.4541\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3580 - val_loss: 0.4344\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3812 - val_loss: 0.4310\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3552 - val_loss: 0.4393\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3782 - val_loss: 0.4273\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3658 - val_loss: 0.4318\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3374 - val_loss: 0.3760\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3599 - val_loss: 0.4340\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3869 - val_loss: 0.4680\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3719 - val_loss: 0.4233\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3683 - val_loss: 0.4471\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3734 - val_loss: 0.4255\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3329 - val_loss: 0.4126\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3601 - val_loss: 0.3907\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3668 - val_loss: 0.4403\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3367 - val_loss: 0.4174\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3422 - val_loss: 0.4335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3371 - val_loss: 0.4256\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3200 - val_loss: 0.4008\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3456 - val_loss: 0.3966\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3171 - val_loss: 0.4050\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3274 - val_loss: 0.4559\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3414 - val_loss: 0.3956\n",
      "starting round 5\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2708 - val_loss: 0.2672\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2585 - val_loss: 0.2508\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2632 - val_loss: 0.2698\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2533 - val_loss: 0.2526\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2481 - val_loss: 0.2474\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2650 - val_loss: 0.2412\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2532 - val_loss: 0.2728\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2512 - val_loss: 0.2883\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2427 - val_loss: 0.2453\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2273 - val_loss: 0.2412\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2362 - val_loss: 0.2854\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2550 - val_loss: 0.2971\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2393 - val_loss: 0.2226\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2212 - val_loss: 0.2392\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2270 - val_loss: 0.2747\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2283 - val_loss: 0.2692\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2361 - val_loss: 0.2317\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2261 - val_loss: 0.2138\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2166 - val_loss: 0.2265\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2218 - val_loss: 0.2252\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2063 - val_loss: 0.2095\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2396 - val_loss: 0.2232\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2417 - val_loss: 0.2352\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2148 - val_loss: 0.2038\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2294 - val_loss: 0.2600\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2159 - val_loss: 0.2305\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2001 - val_loss: 0.2064\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2130 - val_loss: 0.1927\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2188 - val_loss: 0.2200\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2204 - val_loss: 0.2773\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1965 - val_loss: 0.1861\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2123 - val_loss: 0.1989\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2233 - val_loss: 0.2239\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1928 - val_loss: 0.2157\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1987 - val_loss: 0.2414\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1929 - val_loss: 0.2083\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2380 - val_loss: 0.2572\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2211 - val_loss: 0.2026\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2142 - val_loss: 0.2109\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1925 - val_loss: 0.2074\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2032 - val_loss: 0.2298\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1874 - val_loss: 0.2127\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1984 - val_loss: 0.2215\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1979 - val_loss: 0.2099\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1916 - val_loss: 0.1866\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1844 - val_loss: 0.1793\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1895 - val_loss: 0.1947\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1839 - val_loss: 0.2043\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1754 - val_loss: 0.2179\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1827 - val_loss: 0.2269\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1681 - val_loss: 0.1912\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1750 - val_loss: 0.2055\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1833 - val_loss: 0.1897\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1884 - val_loss: 0.1969\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1860 - val_loss: 0.1626\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1768 - val_loss: 0.2084\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1957 - val_loss: 0.2020\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1623 - val_loss: 0.2003\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1620 - val_loss: 0.2076\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1764 - val_loss: 0.1429\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1793 - val_loss: 0.1755\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1744 - val_loss: 0.1762\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1777 - val_loss: 0.2076\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1660 - val_loss: 0.1726\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1624 - val_loss: 0.1939\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1600 - val_loss: 0.2374\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1496 - val_loss: 0.1849\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1633 - val_loss: 0.1675\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1655 - val_loss: 0.1998\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1729 - val_loss: 0.2283\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1614 - val_loss: 0.1632\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1586 - val_loss: 0.2135\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1628 - val_loss: 0.1858\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1542 - val_loss: 0.1856\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1546 - val_loss: 0.1755\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1613 - val_loss: 0.1600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1761 - val_loss: 0.1457\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1488 - val_loss: 0.1586\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1261 - val_loss: 0.1788\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1423 - val_loss: 0.1722\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1697 - val_loss: 0.2645\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1603 - val_loss: 0.1779\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1476 - val_loss: 0.2065\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1318 - val_loss: 0.1870\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1313 - val_loss: 0.1994\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1642 - val_loss: 0.1559\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1377 - val_loss: 0.1168\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1290 - val_loss: 0.2084\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1357 - val_loss: 0.1835\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1500 - val_loss: 0.1229\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1440 - val_loss: 0.1507\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1597 - val_loss: 0.1646\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1235 - val_loss: 0.1304\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1293 - val_loss: 0.1681\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1362 - val_loss: 0.1487\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1343 - val_loss: 0.1958\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1252 - val_loss: 0.1479\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1293 - val_loss: 0.1641\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1128 - val_loss: 0.1510\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1391 - val_loss: 0.1773\n"
     ]
    }
   ],
   "source": [
    "ID = 'data'\n",
    "bcnn_post_nocorr, bcnn_proposals_nocorr, bcnn_time_nocorr = run_bnn(total_runs=1, num_rounds=6, seed=3, \n",
    "                               ID=ID, correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import scipy\n",
    "\n",
    "#get true posterior from mcmc run\n",
    "subset_exact_samples = np.load('exact_mcmc_post.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conv(proposals):\n",
    "    for theta_small in proposals:\n",
    "        f = plt.figure(figsize=(15, 10), constrained_layout=True)\n",
    "        gs = f.add_gridspec(3, 5)\n",
    "        #BCNN KDE\n",
    "\n",
    "        def multivar(grid, m, var, xlabel='', ylabel=''):\n",
    "            ax = f.add_subplot(grid)\n",
    "            x, y = np.mgrid[-2:2:.01, -1:1:.01]\n",
    "            pos = np.dstack((x, y))\n",
    "\n",
    "            rv = tfd.MultivariateNormalFullCovariance(loc=m, \n",
    "                                                 covariance_matrix=var)\n",
    "\n",
    "            ax.contourf(x, y, rv.prob(pos))\n",
    "            ax.set_xlim(-2,2)\n",
    "            ax.set_ylim(-1,1)\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "            return ax\n",
    "\n",
    "        #BCNN\n",
    "        mcmc_mean = subset_exact_samples.mean(axis=0)\n",
    "        c=0\n",
    "        c1 = 0\n",
    "        for i, res in enumerate(theta_small):\n",
    "            m = res[0]\n",
    "            var = res[1]\n",
    "            if i < 4:\n",
    "                ax = multivar(gs[0,i+1],m, var, xlabel=f'round {i+1}')\n",
    "                ax.scatter(mcmc_mean[0], mcmc_mean[1], color='C3')\n",
    "            elif i < 9:\n",
    "                ax = multivar(gs[1,c],m, var, xlabel=f'round {i+1}')\n",
    "                ax.scatter(mcmc_mean[0], mcmc_mean[1], color='C3')\n",
    "                c+=1\n",
    "\n",
    "            elif i < 15:\n",
    "                ax = multivar(gs[2,c1],m, var, xlabel=f'round {i+1}')\n",
    "                ax.scatter(mcmc_mean[0], mcmc_mean[1], color='C3')\n",
    "                c1+=1\n",
    "\n",
    "        #MCMC Gaussian approx\n",
    "            cov = np.cov(subset_exact_samples, rowvar=0)\n",
    "            mean = subset_exact_samples.mean(axis=0)\n",
    "\n",
    "            x, y = np.mgrid[-2:2:.01, -1:1:.01]\n",
    "            pos = np.dstack((x, y))\n",
    "\n",
    "            rv = scipy.stats.multivariate_normal(mean, cov)\n",
    "\n",
    "\n",
    "            ax = f.add_subplot(gs[0, 0])\n",
    "            ax.contourf(x, y, rv.pdf(pos))\n",
    "            #ax2.scatter(target_theta[:,0],target_theta[:,1], color=\"red\", label=\"true\")\n",
    "            ax.set_xlim(-2,2)\n",
    "            ax.set_ylim(-1,1)\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_xlabel('Gaussian fit')\n",
    "            ax.set_ylabel('MCMC (true)')\n",
    "        pdf.savefig(f)\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-4e0afb061473>:52: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax = f.add_subplot(gs[0, 0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"regression_withcorrection.pdf\")\n",
    "plot_conv(bcnn_proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-4e0afb061473>:52: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax = f.add_subplot(gs[0, 0])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEAAAAHsCAYAAADSGdh9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvJUlEQVR4nO3dfbAl6V0X8N8zO3sns9nJMCajW+66L9mC2TKrxDWiLgkC6y4FxqjFWxCoEIoqoBQt9Q+1SlOKIggoFC+aAuTFEElRW1pYCGFjQAlGiUmAMIszwmQzk5lizWYzNTsbJjO7O49/3Htnzj23+3T3Od3n5enPp+pW5vTpc+6zk+nq7m//nt+Tcs4BAAAAULIDqx4AAAAAwNAEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8Q4O8aVbBw7nwwdfMcRXQxGee+ETn8w5H+/6OcfWeF0/fOvC3/HSy1JERNzymcWXPz9w5YWFv2MIji0YxjzH1taBw/nwLUeGGhJsvOdefMY5CwYw65w1SABy+OAr4uE//NVDfDUU4d0XfvDsPJ9zbI3XlQfvnOtzF09szXz/2Olrc33v4ZMX5vrc0BxbMIx5jq3DtxyJh1/1lUMMB4rw7qf/jXMWDGDWOcsUGIA1N1T40XafKvOOCQAAVkUAAlCgLsHGvCEIAABsEgEIQGHmCTSEIAAAlE4AArDGuk41EWQAAEA1AQhAIRYNP4QnAACUTAACsKa6VH8ILwAAYDYBCAA3CFIAACiVAARgwwktAACgmQAEYA21nf4i/AAAgHYOrnoAAKyXiye24tjpa437XXnwzjh88sISRgTrpy6kdEwAwPoSgACsGdUfsL6ajs/d9wUhALB+TIEBAGhw5cE7O63M1GVfAGA5BCAAG0j1ByzPvGGGEAQA1osABGCNrMsNk4AFti16TK7LMQ0ACEAANo5wApajr/BCCAIA60EAAgAwpe/QQggCAKsnAAFYE21ukFR/wPCEFQBQJgEIQMEu33/9xg/QbMjwQ7ACAKslAAHYEF2qP6pCj65BiGoTAABKIgABWAN9PhluCjlUg0C1ZVRoqAIBgNURgABsgLbVGG3DDSEI7CWYAIDyCUAACiHUgPkIPwBgHAQgACvWx83XPOGHwARWQ+ACAKshAAFYc03TXwQZML95w4iLJ7Y0CgaADXNw1QMAYHUu3389jpyRhUMbVYHH5LZjp68tczgAQEeuegHW2KqrPzzhpmRtqz/aVnt0OV5MgwGA5ROAAKzQIjdBpr7A8LqGgEJDAFhfAhCAkROkMEZtwsd5wwwhCACsJwEIwJqadRMltIBhLRpiCEEAYP0IQABWRA8AWI2mY094AQBlEoAAbBjVHzCcPsOPpu8SggLAcglAANaQJ9AwDKEDAIyXAARgBea9CRuq+kNVCQwTPAozAWB9HFz1AADYyw0TDGNW8Oi4g+W59sBdte9tnTq/xJEAYyMAAdgQXao0br/v0o0/P//U0SGGA6My6/g7ckZBLbQxK/iY3kcQAgzBGRugILffd2lP+LG7DcZukeqPpvCx6X3VJdAu/Fhkf4A2BCAASzZUE8ZZQYcQBObTtvJq3j46mrJSumsP3DV3mCEEAfomAAFYI3VPipturtoEHEIQ2G9WdUbXUEMzYdirjwBDCAL0SQACsOH6CjbcvFGqeaosHA8AUB4BCMCam3Uj1jX8UAUCN81bcTVL3Wf1AWFs+qzcUAUC9EUAArBEluGE9abyAxY3RGAhBAH6IAAB2FCqOaBZXeg4ZOAoRGHMBBXAOhOAAKyxuhupRcIPwQlUE1wAQNkOrnoAAJj+AkPoUv0xT6+d5586Ot/AoFBtqj8u3X+o9r2jZ642fv/WqfOdxwWlqzvfHT55YckjWX8qQACWZJ6VKKqo4IDlmXW8zXqvKlARdFKypvDj0v2HZoYfbfcBbrry4J0zry+b3h8jAQjAmlKOD8uxyFQzgSQ06xpqzNpfjxHY1iXYEILcJAAB2CB93Wy5aaN0izY/7XKMOJ4Yu1mhhIoO6N88gYYQZJsABGDFlMXD6lRVfwg0oB+LhB+CE6gmyFiMAARgCbqerEx/gf4NGTZWhSZtj2MXs2yyuuqPPgIMIQjstej5wvlGAAKwMTyVhn6p/oBhtAkuLt+T4vI9aa7v1weEMeorvBh7CGIZXIAVMv0F+jfvxd2i4cft912yNC6j0jWIqAo8drcdOZt7GROUaOyhRZ9UgACsGU+loX/CRliOuuqPpmqPuvdNgwH6pAIEYGDLSO0fu/v0vm1PnDsx+O+FTTUdNNaFjFXHVoTjC9pWf3SZ5nL5nqQSBKY0XUfWBfzHTl+b+Z2HT15YaFybSgUIwIaru0Gr2w4l6zNwnHUMOb5gvz6qNaoCk6rv1QeEMZh1Trt4YmtmdaPKx2oCEIAVqToxdZ3+4iYMmk0fa22qP9ocW44/uKkqpJi3yem8n4OxaBtuzNpvrH1FBCAABXODBt0tctzo18MYtKm+qAsxrt59bc8PUK0uoOha2aESZC8BCMCGWjTccKMGjgMYQlX4URd4CEGgvXnDDCHITQIQgAEtWl7YtTHjovvCJmtzvFVNM5vU9Xhp2r/p90EJmnp/NIUcVe9PhyhWg2FMxjo9ZRkEIABrwo0S9M9TL+hX0/SX6eCibYWHShCYbdb57PL91xuvI6s+P8agxTK4ACuwyE2Zig7ox3SFlWMLuptVmdE11Lh697U4dE5oybhVhRJ1143Tocfk6yNn1DpU8bcCsKbWvTfBWNePZ3Ota5WVY4lS9L16i9VgoF7TOW1dz3mrpgKEwU2nmC70AOhblydmVRap/njs7tPxxLkTc38eNkWb1V92VVV/3HvXM/u2fez88X2fUwUCN1Wdy+YNNy6e2Ipjp8c93UwAwmDq5pRdefBOIQij0GVeZdsTmRJ96EfbCquvP/b+Pa/fcfHhIYYDG2ly+ktTtUZV+LG7fToEaevaA3fF1qnzc30W1lEfzbyn9zUVZi9/GwBLtoqmjIITqFd3fEyHH3XbgL2mqz/qwo+278NYTV8zmtayOAEIg5hMLy+e2LrxA7RT9XRaiAHz63rRKOiAvbpMf5k0T7hR1zzVUriMWd157Pb7Lt346fK5XWNbCUYAQu92D6JZocfYDjQAlmtW6N40/UX4Ac3qpr9Mhhddwo+6fTVCZSym74+aHh5XhR6zgpC231s6AQi9mgw/qoz9gGM8huj/AVRbJFSfp7JKQALAMk1fK677SoHrTBNUercbckwfqBrwQDumv8DqCDdgfk3VH4/ecWrP6/c8/cDgY4Ixuv2+S/H8U0dvvNYM9SZ/C/Rm8glc1RNtT7lBFRSsgvMPLGa6/0eX1V8itoOP6fBjdzvQbfqL6o/FCEDo1cUTWzcuNJsa8gDAsk2ek6Yrq1R/QD/mXdXFajCw32SI3+W+yj1YNQEIvZhOLasa8gD7tXkyvcrpL8dOV3fih3W2TpVWSo4Zi7qVW5qqPFSBAMukBwi92a3+2A07Jm/anjh3YlXDgo0iLIRurCoGq1M1/WWyikO4Ad1Nhvizqj+qHpC552rmsQQLq7r4bHpiffjkhaGGAytXd0O2Tk+lF+UYpjSmv0A7k/0/hlRXUQKl6TPIn74H82BtPwEIvZis/tg98L7+2PtdUMKCrP4Ci6l7eubYgnamG6BWqQorVH9Af9pUf9COAIRBCD5g/U0ujwashmoqSjJvE1NhCexX1yeuKfyoe9+KaNv0AGEhkyVbu9Ufwg9op8uJ6NXvuxive9fTcfuzL8Tzr7w1PvjmO+Kjbzi253h7x8WHhxgmFG332Lr12ZdHHM/x0luvxfVHXlz1sGDj3fWrl+M17/xU3Pbsi/EHrzwYL/+m5+LAIy9ERMTjzz204tHBemozXbrumpB2VICwsMmlb2c5cuaAFSVghrp5mq9+38V4/Y+cjyOffCFSjjjyyRfi9T9yPt7y4Q/s2W/R8NFqFZSgS6+dvcdWivSJA3HL9x+KA+8d5vmQcyAlqWqAuuut//d/x0NvfyZe/skXI+WIl3/yxYjvOxzX33trRER8xSs+vKxhQlG+5ez/qrwmfPX7Lq56aBvD1S69qrsBmyy1V+5LyYZoZPW6dz0dt17Le9679VqOW36inKaqMI9Fj7eqYytdTY4tqFHVALWq/8dr3vmpOHg1T+2YIn78Zb2OZ+vU+V6/D5atzXls8gFZ3TXh6971dO9jK5UAhF5MNj+d9I6LD1uOCWKxFWBuf/aF6jeeqX/6BjRzbMFsbRqgVrnt2ZppZI4tWEjdeav2fMY+AhDmtptYaqgDw3r+lbdWv3E8V28HIqJ5BRjHFvRnsgHqH7yyZhqZYwtaqbq/euzu07XnrdrzGfsIQFhI26fa+n/AXtMntlnrtH/wzXfEC1t7n5rlQ9vNGqdpQgztdTm2ZpmsdLS6EkQ8+bV/KF48NFXtcShHfONnbrxs6gNy6Nz+a8yjZ672Mj7YVFXnrRe2UnzwzXesaESbp1WXr5TS6yLiDRHxRyPiSkScjIj35Jx1W6HW7vSX5586Gkd2tun/Ae1MTinb7ey92/E7jl+3UgX0YPfY+sKfPbtdmt/zKjAaCzNGj95xKs7fsX3l95p3fipe/uwL25Uf3/iZG6vAAPtVPViefkBWdU2Y3notPvpQ8yowzknbZgYgKaW3RsS3RcRTEfGhiDgdES+LiNdHxN9PKZ2MiH+ccz439EDZDJbhhGF89A3H9i17O7S6qi1BJiX5/Df9n3jhTav53Y4lNtWsFWB2nf+CI/Hn3vi7SxgNjEvlNaGyhNaaKkBui4jPzzlfqXozpfTaiPjsiBCAsM+N6o+d6S8u9ChdXSfvRRqgAu051mBzPP7cQ6seAjBCM+tgcs4/XBd+7Lz/mznn9/Y/LNZd1Y3e5BxoK78AMKQ+l5zuap5qR32w2HRtl8Dt25GzGqdSplWexyaN7SF12x4gnxMR/zYi/kjO+cGU0p+MiDflnP/5oKNj40w3gtP8FPqjwSkAJXrP0w+segjASLTthPKjEfEPI+KFiIic80ci4s1DDYrNM931fjf82DW2ZBFmaVoBZrIBal9UZcEwHFsA9KluCVz60aoCJCJuyzl/IKU9DY8sP8AeVUv/qf6A9TR9vOoMTmmqLiCHNnlcOabYdNceuKv1vvfe9Uwvv/Nj54+33nfr1PlefidsqjbTMS3Nvl/bs/MnU0r3R0SOiEgpfUVE/P5go2KjTF/kHTlzYM/UF9UfAKzSdJXVIqx2BovTABVWZ+wPqNtWgPyNiPiRiHggpXQhtpfF/brBRsXGmQ5BhB/QL/0/oCzOj4zB4889FF/xig93/tyhc/tXdDp65mofQ4LimZo5W6sKkJzzR3POfzEijkfEAznn1+ecPzboyNgIVQni2FNFxqm0JXDrjmM3bdCd8yLcNF39MasBqhVgYNuioYZpmTe1XQXmbVOvIyIi5/ztA4yJDXD45IUbN3xulGB9KM+H4UwfX9MrnwH7TVaBmPoC62WM92tto6BPT/y8FBFfGhH3DjQmCjDGgwnaWMUKMEC9IUJDT9oYm6bmpY8/91Bj+NGlASpQTTDfrFUFSM75X02+Til9b0T80iAjYuMJPwAAaFI1/aWq/8c0K8DAfEzJbF8BMu22iGi/NhZFqgo6hB8ArMLQ/XZmTX/pyrmSks3q6TEvDVBhfqoS92rbA+S3Y2cJ3Ii4Jbaboer/gYs4WIJFV4CZvlGbLol0YmTT1DUdXpVZZcaetkG1yaCkavqLBqiw1xPnTsycKm36Szttl8F948SfX4yI/5dzfnGA8QAUY1NXgIGxecfFh2cGjV36hAgUAVjEkTMH9vWMazJPVeJYH2Q3nqVTSrdExC/lnM/u/FwQfgDctG5Po4H+VIUfiy5HCKVrmgZT936b/h8wJtOVHFXnn1nnpMlQXkXitsYKkJzzSyml0ymlu3PO55YxKABWx9LWjFFVFYhlpWG2Q+e24urd3W6qpsOPptVfpvt/aIDK2DWF8Ka/zNZ2CsyxiHgypfSB2F4KNyIics5vGmRUACPQ9xK4btZgMfMcQ137fwgSKdXHzh+Pe+965sbr9zz9QDx6x6k9+7RtkKr/BzCUtgHIPx50FAAj0HU+J7B+2pYaA82Bx2T1h+kvUO35p47ue2g2a99ds6a/jDmMb3um/rKc83+f/ImILxtyYAAAfVAODEDpnOvaaRuAPFqx7Uv7HAgA/bMELuw3bxPTpuMJxq6pn0fdvpPVH5PTX/T/YKymr8+azjeu79qb+TeTUvrWlNJvR8SJlNJHJn6eioiPLGeIAADrbfpiU/8PSjYZUswzdaVLUAJsqwtBmsIRq7/s1dQD5D9ExC9GxHdGxD+Y2H455/ypwUYFsCHqlsC9eGK5c5n7aoBqBRiopvoD2pluhlr1/qS66g8Ym2OnrzVeP7Y59zRVf4z9mq6pNualnPPHcs5fk3M+O/FzI/xIKd0+8BgBAHrVZRrMvFNmoCTT01Fmqavw6FL50eX3wSZqCiJMYxlGUwXIz6WUfjMifi4iPpRz/nRERErp1RHxRRHxVRHxoxHx+JCDBABYV22mv0DJDp3biqt37/133ybs6DJ9Rv8PaOZ81GxmrJRzfiQi3hsR3xwRT6aULqWUno2In46IOyLiLTln4QfAGvLUGmZrc4xU7TPP9JexlxzDtOnww/QX2K9LFUibfZ2LWqwCk3P+hZzz1+ac7805H805vzLn/HDO+Ttyzk8vY5AAm+7y/df3vG67nnsbbft/6BDOmLTtoD8rBBEiMmZNFRfTgcU8zVDrmP7CWFVVbLS5XqvaR/VHNVe/AMCoTQcdT5w7URt+NAWJLjihWdfqD9NfGLtZIUjb8EP1x7amHiAAjIQbNzZZm+75s6j2gMVV9QKZfn/adPih+gOqqdzth79FgDXw2N2n5/pcX8vfzuKJAWybdxqZY4hSTIcTVZUbh85t7Qs6qrYB1eeHRR9Iqf6YbeaZO6X0Z1JKX1qx/ctSSn96uGEBsAhPs2G/eZqXdvmsKiq4aTf0mBV8tKn+MP0F2nMeatb06OJfRsTvVGx/MiK+p//hAGyOKw/eudLf36X6QwNUAIYw7+otVn2BeoKM4TRdAR/JOZ+d3riz7VXDDAlgsy3ShwAY1jxVIFWfMf2FseqjR0dV+KH6A/bqGoLU7e88tFfT2fvYjPdu63MgAFSrqvRYRu8P2HR9VDq1DUw8raNEbQOILtUcKj9gr1kBRZtzy7HT14QfHTRdGfzXlNJ3pJTS7oa07dsj4peHHRoAVZrCj3n6fzhxMiZtQ426/Uwhg/3aBBt1+1j5BerVBRyzgg/qNS2D+/ci4sci4vdSSr+5s+1zI+KDEfFNA44LgAkqPqBfzz91NG6/79LM99sSIDI2R89cjUv3H9q3fTLguHxP2ret7ruqmP7CmBw+eaGxt1zXsMM5qNrMACTn/OmI+JqU0qsj4jU7m5/MOX908JEB0AsNUBmzI2cOxOX7r1e+N08/EMcPtGOqC7COmpbBfSil9FBEfFZEXNj5+ayJ7QAAS1X3VGvoUmDhB2NUV4nRx7QV1R8wDNUf9ZqmwHwwIk5GxCd3XqeJ93JEfPEQgwJgPvP0/wDmZ/oLzEffD9irzTSYtt9DvaZHGX83Ip6LiCsR8RMR8Zdzzl+08yP8AGihrvx+XWigRen6qNxQ/QH7zRtizPqc6g/GbNHwQvjRbObZPOf8/Tnn10fEt0XEH4uI96aUfjal9NplDA6AxczT42CXkyhsqws/hIeMxaxQomsIIvyA2ea9/nLd1k6rxxk7TU9/LiKeiIjPi4jPGXJQAOuujxLFvrWZ/uIpNmM177/9eT7nIpSxaROCHD1z1bQXGIjzTnsze4DsrP7y5oj4KxHx8Yh4V0T8i5zzlSWMDQCgk2Onr8XFE1u9fNes8EP1B+y1aLih+gNu2g00mh64CT66a2qC+nsR8ZHYrv54LiLujohvTWm7F2rO+V8POjqAkXji3Il47O7Tqx4GFG3WkrhV+87DxSil2jp1Pq49cNeqhwGjUheEONfMrykA+fbYXu0lIuL2gccCsPH6evLcVdX0lzb9PzzFZmzahCBN4YfjBvql+gNmE3j0Z2YAknP+J0saBwAD6/JE24mWTdY0DWaRXjjCD8ZsiCoQ4QewTDOvAFJK35NS+uaK7d+cUvqu4YYFAFBvHUO6dRwTrDPhB7BsTY9AvjgifqRi+49GxBv7Hw4AXc07/QXoRvUH9BdaCD+AVWgKQA7lnPP0xpzz9YhIwwwJgGVwM0fJ+v733fR9qj8Yk0XDC+EHsCpNAciVlNJnT2/c2WYpXIAVq6r+qLJIzwMAmDZviCH8AFap6Yr4bRHxiymlb0gp/Ymdn7dGxH/ZeQ+AwniSTSn6qgJR/QHVuoYZwg9g1WYGIDnnX4yIvxoRXxQRP7nz80UR8eU5518YeGwAo9K2mqNpf/0/GItlBA+misFsW6fONwYbbfYBWIaZy+BGROScT0bEW5YwFgCAXjUtidv02SaqP2CbgAPYBDMDkJTSf571fs75Tf0OB4A2ulSLVPX/8FSbMZknBHGMAEB5mipA/nxEfDwifiYifj2s/AIwqCfOnYjH7j499+dNf4FqbUOQLsGH6g8A2CxNAcgdEfFoRHxNRPz12G5++jM55yeHHhgA1br2CunCDR2b5vDJC3HlwTtb7bsbblQFISo+AKB8MwOQnPNLEfHuiHh3SulQbAch/y2l9E9zzj+0jAECrJu2N1vzmlUFMmT4AWPRR9ghLASAzdPYBHUn+PhLsR1+3BsRPxAR/2nYYQEwrSn8qJr+ov8H9E/4AQCbqakJ6r+PiAcj4hci4p/urAgDwMBUekB7XabBAADj1VQB8nUR8emI+NsR8bdSutEDNUVEzjm/YsCxAdBSH81PPdWGZo4TANhcTT1A9tdOA7ARqqa/QKmWUQUi/ACAzebqGGAFVrVcrf4fAACMlQAEYMOtKkyBMVH9AQCbTwACUKCu01/c3FGCof4dOz4AoAwCEIAN1qX6w/QXxqDvsEL4AQDlEIAAAFQQfgBAWQQgABuqrvrD6i+MXR/BhfADAMrjKhlgRdaleakbPUq0yL9rxwQAlEkAAjCwISoyuoYn+n8wRl2DjMMnLwg/AKBgB1c9AAD6Y/oL7LUbaFx58M7GfQCAsglAAFbo+aeOxu33Xer8GaAbIQcA4FEhwAaZJ/yYNf3FTSEAAGMhAAFYsbahRtN+pr8AAEA9V8sAAABA8QQgAGtgVnXH808dnbv6w+ovAACwTRNUgDWx7Oam+n8AADAmKkAAlmDI/hx6fwAAQDNXzQCFMv0FAABuEoAAAAAAxROAAGyweae/6P8BAMDYCEAACmT6CwAA7CUAAejRrOCh72almp8CAEB7rp4BNtAi4YfpLwAAjJEABKAwpr8AAMB+AhCADWPqCwAAdOcqGmCJVh1emP4CAMBYCUAANkhTgGL6CwAAVBOAACzZvFUgq64eAQCATeZqGmADtAk/VH8AAEA9AQjACqyimkP/DwAAxkwAAtCztpUYbUKQI2cOqP4AAIAeCEAAVmhWuKHnBwAA9OfgqgcAMHbLCDpMfwEAYOw8XgTYcKa/AABAMwEIAAAAUDwBCMAAllWV0eb3mP4CAAACEIDOBAoAALB5BCAAG0rvDwAAaE8AAlAw1SoAALBNAAIwkCErNFR/AABANwIQgA3TNvxQ/QEAADcJQAAAAIDiCUAANoipLwAAMB8BCMCAVhVYmP4CAAB7CUAANoTqDwAAmJ8ABGBgfQQXwg8AAFiMAARgzXUNP0x/AQCA/QQgAHPoGjLMW8Gh8gMAAPohAAFYkq5hxjzhh+oPAACoJgABWKK2oYbKDwAA6JcABGDJmsKNecMP1R8AAFDv4KoHADBGKjwAAGC5VIAAAAAAxROAAMxpnaacrNNYAABgHQlAAAAAgOIJQAA2nOoPAABoJgABAAAAiicAAdhgqj8AAKAdAQjAAgQQAACwGQQgABtK+AIAAO0JQAAAAIDiCUAANpDqDwAA6EYAArAgYQQAAKw/AQjAhhG4AABAdwIQgA0i/AAAgPkIQAB6IJgAAID1JgAB2BBCFgAAmJ8ABGADCD8AAGAxAhCAnggpAABgfQlAANacYAUAABYnAAHoUd9hhfADAAD6IQABWFPCDwAA6I8ABKBnfQQXwg8AAOiXAARgAIsEGMIPAADonwAEYCDzBBnCDwAAGIYABGBAXQIN4QcAAAxHAAIwsKZg4/DJC8IPAAAY2MFVDwBgDAQcAACwWipAAAAAgOIJQAAAAIDiCUAAAACA4qWcc/9fmtIzEXG29y+GctyTcz7e9UOOLWjk2IJhdD62HFfQyDkLhlF7bA0SgAAAAACsE1NgAAAAgOIJQAAAAIDiCUBWIKX0R1JK/yGl9NGU0odSSv8zpfTXlvB7X5dS+oGevusNKaUnU0q/mVK6M6X0+M7216aUvqyP3wEAAAB90QNkyVJKKSLeHxE/lXN++862eyLiTTnnH1zp4DpIKb09In4t5/zTU9u/ISJel3P+mysZGAAAAFRQAbJ8XxwR13bDj4iInPPZ3fAjpXRvSul9KaUP7/w8vLP9C1NKP7/7mZTSD+2EDZFS+q6U0u+klD6SUvrenW1fmVI6mVL6rZTSr05/R0rp83YqT34jpfT+lNKJne3fkFL6jymld6eUfjel9N3T/wEppW+KiK+KiH+WUnrnzphPppS2IuLbI+KrdypDvnqIv0AAAADo6uCqBzBCr4mID894/xMR8WjO+TMppc+OiJ+JiNfV7ZxSemVE/LWIeCDnnFNKn7Xz1tsi4ktyzhcmtk06FRFvyDm/mFL6ixHxLyLiy3fee21E/KmIuBoRp1NKP5hz/vjuB3POP5ZSen1E/HzO+fGU0r0726+llN4WKkAAAABYMwKQFUsp/XBEvD62q0L+TETcGhE/lFJ6bUS8FBGf0/AVlyLiMxHx73aqO3arRP5HRPxkSulnI+I/VnzuaET81E7Iknd+76735pwv7YzvdyLinoj4+P6vAAAAgM1gCszyPRkRD+2+yDn/jYh4JCKO72z6OxHx/yLic2O78mNrZ/uLsff/r5ftfP7FiPi8iHg8It4YEe/e2f4tEfGPIuKPRcSHdipFJv2ziPiVnPODEfGXd79vx9WJP78UgjIAAAA2nABk+X45Il6WUvrWiW23Tfz5aET8fs75ekR8fUTcsrP9bET88ZTSoZ0pLY9ERKSUbo+IoznnX4jt8ORzd7bfn3P+9Zzz2yLimdgOQiYdjYgLO3/+hp7+2yIiLkfEkR6/DwAAABYmAFmyvL3szl+NiL+QUnoqpfSBiPipiPj7O7v8m4h4S0rptyLigYj49M7nPh4RPxsRJ3f+9zd29j8SET+fUvpIRPxaRPzdne3fk1L67ZTSydhedea3poby3RHxnSml34h+Kzx+JbaDGk1QAQAAWBuWwQUAAACKpwIEAAAAKJ4ABAAAACieAAQAAAAongAEAAAAKJ4ABAAAACieAAQAAAAongAEAAAAKJ4ABAAAACieAAQAAAAongAEAAAAKJ4ABAAAACjewSG+9FWvelW+9957h/hqKMKHPvShT+acj3f9nGMLZpv32AIAoHyDBCAvPHdLHH/64SG+GgrxobPzfOqFSwfi+IU/2/dgoCDzHVsAAJTPFBgAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4B1c9AMbjyoN31r53+OSFJY4ENt+1B+6qfW/r1PkljgQAADaDAITBzQo+pvcRhMBss4KP6X0EIQAAcJMpMAyqTfixyP4wJm3Cj0X2BwCAkglAGMy8YYYQBPabN8wQggAAwDYBCIMQYkB/hBgAALA4AQi96yP8EKDAtj7CDwEKAAAIQOiZ4AL602dwIQQBAGDsrALD2rry4J1WhYEal+4/tG/b0TNXVzASAADYDAIQejOr+uPiia3a946dvjbEcGCj1VVsVAUf0+8JQgAAYD9TYOhFXfhx8cTWzPBjdx/gpnnCjzb7mQYDAMCYCUAYTJdgo25fPUVgW9vwY979AQCgdAIQFlYVUsxT1aESBKqrNOYNM6o+pwoEAICx0gMEYI3NCj8u35Nu/PnI2byM4QAAwMYSgLCQLtUfl++/vuf1kTP7C5AuntjSFJXRalOdMRl6VG2fDkIu3X9IU1QAAAhTYOhZVfhx+f7r+8KP3e1Avenqj7rwo+s+AAAwRgIQ5tamQWlTyNEmBNEIlTFoqv7oEmw07asPCAAAYyQAoTfT1R9tKzym99MMFfZWfyxa1WFFGAAA0AOEOU1XZcwbfgDdXb27uk/OoXM3j8PL9ySNUQEAYIIAhN5VhR+333dpz+vnnzq67zNVTVFhDKanpMyq/qgLP3bfmwxBAACAm9xxMrjp8KNuGzDbrPCjymR4YhoMAABjJwChs1nTXyarP26/79LMoEMIAvvVVX+0DT+6hiQAADAWAhBWajIEmQxPNEJlLNqsyDIdatx71zN7fgAAgGYCEBYyq/oDmF/dyi9Vgcd0ENKmCsRSuAAAjI0mqHQyPf2lynT48djdp/e8fuLciV7HBKWo6tMxGWbMU+1hNRgAANimAoS51VV/TJoOP6q2qRaBvaqqP9qEH6bDAABAPQEIvZoMM6rCjzbvwVg0TUNZpKGpZqgAALCXKTC0Vjf9par6Q8AB3cxapna6suPRO07tef2epx/Ys+/Hzh+v/R1Hz1xdYJQAALC5VIDQm65TWYQksF9d89Nd0+FH3TYAAGAvAQhzmbVM7SLBRl0vERib3Sksk9Ufgg4AAJifKTAspCmw+Ppj79+37R0XHx5qOLAxui5D2xR+PHrHqT1TYQAAgL1UgNBK0/K3u9NfJqs/qsIPYL9Z/T8AAIB+CEDobNb0lzYEI1Btt/9H1fQXAABgMabAMAghB/RnevrLV7ziwzf+/PhzD+3bf9ZKMAAAMFYqQJjbbv+PqukvwDAmww8AAKA9AQi9e8uHPxC3ft1tceuXvDxu/brb4sB72xcaHTnjnyRUuetXL8eXfPPZuP7YK+L61x6J6++9NSL2BiJWiQEAgHqmwNCoqQHqpFe/72Lc8qOHIl3d7mUQn0hxy/dvN3i8/siLQwwPNk7XFWDu+tXL8dDbn4mDV3NEpIhPpIjvOxzXI+LAIy8MMkYAACiNx+100tQA9XXvevpm+LEjXU1xy08s1jgVSlW3AsxuA9RH7zgVr3nnp3bCjwlXU8SPv6zT7zp65upcYwQAgBIIQJhLXf+P25+teRr9TKreDuyxuwLMpNueramemjqu3vP0AxERGqACAEAFAQj9On69Znuu3l7j2On9N4FQst0lcKv8wStrZit2PK4mbZ06P/dnAQBgEwlA6NVLb70W+dDem7J8KMdLb50/0Dh88sKiw4KN9uTX/qF48dBUQHIoR3zjZ1YzIAAA2ECaoNKr3Uant/zE1nZ5/vHt8EMDVJjf+S84EhERn/czT984ruIbPxMHHnkhHn/uoRWPDgAANoMAhJm6rACz6/ojLwo8oGfnv+BI/Lk3/u6qhwEAABvLFBiW7h0XH171EAAAABgZAQitNS2B29UT505ERMTzTx2NiIgjZ/xzhC5mTX85dG77eD1ydv5GqQAAUBJTYFg7VoCBarMCD0vgAgDAbB65s9asAAP9OHrm6o0/WwIXAIAxEoCwVPp/QDe7lR2L7gMAAGMnAGEl9P+A/u1Of9nt/wEAANzkrpNezarwUP0B7bXt5TGr+kMDVAAAuEkAwlrRAJWxq6reqAs52k59mez/AQAAYyUAoXdVlR6T26anv9TRAJUxaarWmA47pl+3nf6iASoAAGNlGVwG0WW6i/4fUO1j54/HvXc9c+N1l2anpr8AAMBe7jxZqt3qjyqmv8B82vYLAQCAMROA0ItZwUaVpukvMGaT01iawo3J96umv+j/AQAA2wQgLE1VSFI3/UX/D8aiTUBRF4LUba+b/qL/BwAAY6YHCL154tyJeOzu07Xv7VL9AdWOnM1x+Z5U+V5TJUhT81MAABg7FSAsZDrMmK7yeOLcidrpMZPVH/p/wF5dAo3JfSerP0x/AQCAm1SA0LtZ/UDaVH+Y/gLbDp3biqt3zw4H2wYlpr8AADB2KkBora5Ko+2Ulsn9VH8wZrPCiC7L106HH6o/AACgngCEudQ1L62j7wfUmxVWHDq3tS/oqNrWJTgBAIAxEoDQi1kBx/R7s6o/TH+B6jBjN/RoM+VlOlAx/QUAAPQAoUe7Qcft913a8xoYluoPAABopgKEudVNg3n+qaO14YfqD6g2XbXRNtSY3k/vDwAAqCYAoZNFGpZ27RsCJWszLWVWCHLkbG4Vkpj+AgAA20yBYabDJy/ElQfvrH3/yJkDcfn+643fMx1+WPkF9jt65mpcuv/Qnm1dpreo/gAAgHoeybOwpsqONpUfpr/AYqrCD9UfAABwkwCEzqqqN46cObAv6KjaVvd5GKOqgGKeKg6VHwAA0MwUGHrVVO1RFX6o/oC9qqbCzNq3iuoPAADYSwUIc5mnikPlB7TXVNVx9MxV4QcAAHSgAoRGTY1QF/1uGLOtU+fj2gN3Vb5nagsAAPRHBQhza1vRcez0NdUfsCSqPwAAoJoAhIU0BRuz3lf9Adv6Ci2EHwAAUM8UGFqZNQ1mnuoO4QfsNWsqTNvPAwAA9VSAAGw44QcAADQTgLB0qj+g2jxBhvADAADaEYDQWh/BhfADZts6db51qCH8AACA9vQAoZNFlsQVfkB7u+HGdF8QoQcAAMxHAMJSCD9gPgIPAADohykwdNY1zBB+AAAAsGoqQJjLbqgxazqM4AMAAIB1IQBhIUIOAAAANoEpMAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxBCAAAABA8QQgAAAAQPEEIAAAAEDxUs65/y9N6ZmIONv7F0M57sk5H+/6IccWNJrr2AIAoHyDBCAAAAAA68QUGAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHgCEAAAAKB4AhAAAACgeAIQAAAAoHj/H/3dwYjX2ZyyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"regression_nocorrection.pdf\")\n",
    "plot_conv(bcnn_proposals_nocorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obs need \"data\" folder \n",
    "np.save(f'{ID}/bcnn_{ID}_post', bcnn_post)\n",
    "np.save(f'{ID}/bcnn_{ID}_time', bcnn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
